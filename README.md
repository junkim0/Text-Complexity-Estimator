# Text Complexity Estimator

A machine learning project that fine-tunes a transformer model to predict text complexity scores as a regression task.

## ğŸ§  Concept
Fine-tune a transformer (e.g., bert-base-uncased) to predict text complexity scores (like readability, syntactic depth) as a regression task.

## ğŸ¯ Goals
- **Input**: A sentence or paragraph
- **Output**: A score (e.g., Flesch-Kincaid, CEFR levels, or 0â€“1 complexity)
- Fine-tune a model to learn these scores from text

## ğŸ› ï¸ Tech Stack
| Component | Tool |
|-----------|------|
| Model | bert-base-uncased or DistilBERT |
| Framework | Hugging Face Transformers |
| Dataset | CommonLit Readability |
| Metric | MSE, RÂ² |

## ğŸ“‚ Project Structure
```
text-complexity-predictor/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ readability.csv
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ best/
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate.py
â”œâ”€â”€ predict.py
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## ğŸš€ Setup

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Download the CommonLit Readability dataset and place it in `data/readability.csv`

3. Train the model:
```bash
python train.py
```

4. Evaluate the model:
```bash
python evaluate.py
```

5. Make predictions:
```bash
python predict.py --text "Your text here"
```

6. Run the web app:
```bash
python app.py
```

## ğŸ“Š Model Performance
The model is evaluated using:
- Mean Squared Error (MSE)
- R-squared (RÂ²) coefficient
- Root Mean Squared Error (RMSE)

## ğŸ¤ Contributing
Feel free to contribute to this project by submitting issues or pull requests. 